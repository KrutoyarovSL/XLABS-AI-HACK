{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ДООБУЧЕНИЕ STABLE AUDIO AI\n",
        "\n",
        "### 1. Подготовка данных   \n",
        "- Описание: На данном этапе собираются и подготавливаются данные, которые будут использоваться для обучения модели.\n",
        "   - Что включает:     \n",
        "    - Сбор исходных данных: аудио файлы, аннотации, метаданные.\n",
        "     - Очистка данных: удаление шума, лишней информации или ошибок.     \n",
        "     - Разметка: создание соответствия между аудио и текстовыми транскрипциями.\n",
        "     - Форматирование данных: преобразование аудио в нужный формат (в нашем случае mp3 -> wav) и создание необходимой структуры директорий.     \n",
        "     - Разделение данных: разделение на обучающую, валидационную и тестовую выборки.\n",
        "---\n",
        "### 2. Загрузка предварительно обученной модели Stable Audio\n",
        "   - Описание: Использование уже существующей модели, обученной на схожей задаче (pre-trained model).   \n",
        "   - Что включает:\n",
        "     - Загрузка предварительно обученной модели, которая предоставляет основу для дообучения.     \n",
        "     - Проверка совместимости модели с текущими задачами и доступными данными.\n",
        "     - Анализ параметров модели: размер, архитектура, функции потерь, методы оптимизации.   \n",
        "     - Зачем нужно: Предобученная модель помогает ускорить обучение и повысить качество, поскольку она уже \"знает\" базовые аспекты задачи.\n",
        "---\n",
        "### 3. Настройка модели и компонентов\n",
        "   - Описание: Этап адаптации модели к специфике задачи и среды обучения.   \n",
        "   - Что включает:\n",
        "     - Настройка гиперпараметров: скорость обучения, размер батча, количество эпох.     \n",
        "     - Адаптация архитектуры модели: добавление новых слоев, изменение функции активации.\n",
        "     - Настройка компонентов: выбор оптимизаторов (Adam), функций потерь (MSE).     \n",
        "     - Подготовка среды обучения: выбор фреймворков (PyTorch), настройка GPU.\n",
        "     - Добавление регуляризации или других методов для предотвращения переобучения.\n",
        "---\n",
        "### 4. Цикл дообучения   - Описание: Основной процесс обучения модели на предоставленных данных.\n",
        "   - Что включает:     \n",
        "     - Загрузка данных в модель в виде батчей.\n",
        "     - Прохождение прямого распространения (forward pass) через модель.     \n",
        "     - Вычисление функции потерь для оценки ошибки.\n",
        "     - Обратное распространение (backpropagation) для обновления весов модели.     \n",
        "     - Валидация на отложенной выборке для проверки качества обучения.\n",
        "     - Повторение процесса в течение заданного количества эпох.   \n",
        "     - Особенности:\n",
        "     - Мониторинг метрик (точность, потери, время обучения).     \n",
        "     - Возможность остановки обучения при достижении заданных условий (early stopping).\n",
        "---\n",
        "### 5. Сохранение модели\n",
        "   - Описание: Этап фиксации текущего состояния модели после успешного обучения.   \n",
        "   - Что включает:\n",
        "     - Сохранение весов модели в файл.     \n",
        "     - Сохранение структуры модели и гиперпараметров.\n",
        "     - Версионирование: создание уникальных версий модели для управления изменениями.     \n",
        "     - Оптимизация модели для дальнейшего использования: преобразование в формат подходящий для внедрения.\n",
        "---\n",
        "### 6. Проверка качества модели\n",
        "   - Описание: Оценка обученной модели на основе ее работы на тестовых данных.   \n",
        "   - Что включает:\n",
        "     - Тестирование на данных, которые не участвовали в обучении.     \n",
        "     - Расчет метрик качества: точность, полнота, F1-score, среднеквадратичная ошибка и др.\n",
        "     - Анализ ошибок: выявление случаев, где модель дает некорректные результаты.     \n",
        "     - Сравнение с базовыми метриками (baseline) или предыдущими версиями модели.\n",
        "     - Генерация отчетов и визуализация результатов (например, графики точности/потерь, confusion matrix)."
      ],
      "metadata": {
        "id": "GqOVG5hlY0He"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirements"
      ],
      "metadata": {
        "id": "wilnP2FQO7eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch==2.0.1\n",
        "! pip install torchaudio==2.0.2\n",
        "! pip install torchvision==0.15.2\n",
        "! pip install transformers>=4.41.0,<5.0.0\n",
        "! pip install diffusers==0.17.0\n",
        "! pip install flax==0.6.10\n",
        "! pip install jax==0.4.27\n",
        "! pip install jaxlib==0.4.27\n",
        "! pip install sentence-transformers==2.2.2\n",
        "! pip install huggingface_hub==0.23.0"
      ],
      "metadata": {
        "id": "gtHHkJmTOu2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Логин hugging face"
      ],
      "metadata": {
        "id": "EfRkdK_qPC-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Логин в Hugging Face (введите свой токен безопасно)\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "Xy4goWyuOycM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необходимые импорты"
      ],
      "metadata": {
        "id": "Md_yYNBpPGyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import os\n",
        "from diffusers import DiffusionPipeline, UNetConditionalModel\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "bQXtFlqRO0Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подключение к Google диску"
      ],
      "metadata": {
        "id": "73ioO_jKPKWO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvKMjQrPngGh",
        "outputId": "5205ef89-d5b7-4fa4-f13c-0727840d98c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка модели"
      ],
      "metadata": {
        "id": "Ej4pkyQvPTV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка предварительно обученной модели Stable Audio\n",
        "model_id = \"stabilityai/stable-audio-1-0\"\n",
        "pipeline = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipeline.to(\"cuda\")"
      ],
      "metadata": {
        "id": "1ZlSBxL3O2_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка данных"
      ],
      "metadata": {
        "id": "OsInnpfhPVj-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpGcHWx09enD"
      },
      "outputs": [],
      "source": [
        "class AudioTextDataset(Dataset):\n",
        "    def __init__(self, tsv_path, audio_dir, tokenizer, max_audio_length=16000, max_text_length=128):\n",
        "        self.data = pd.read_csv(tsv_path, sep=\"\\t\")\n",
        "        self.audio_dir = audio_dir\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_audio_length = max_audio_length\n",
        "        self.max_text_length = max_text_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        text = row['sentence']\n",
        "        audio_path = os.path.join(self.audio_dir, row['path'])\n",
        "\n",
        "        # Загрузка аудио\n",
        "        audio, sr = torchaudio.load(audio_path)\n",
        "\n",
        "        # Преобразование в моно и ресемплинг до 16000 Гц\n",
        "        if sr != 16000:\n",
        "            resampler = torchaudio.transforms.Resample(sr, 16000)\n",
        "            audio = resampler(audio)\n",
        "        if audio.shape[0] > 1:\n",
        "            audio = torch.mean(audio, dim=0, keepdim=True)\n",
        "\n",
        "        # Обрезка или дополнение аудио до max_audio_length\n",
        "        audio = self._pad_or_trim(audio.squeeze(0), self.max_audio_length)\n",
        "\n",
        "        # Токенизация текста\n",
        "        tokens = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_text_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"audio\": audio,\n",
        "            \"input_ids\": tokens.input_ids.squeeze(0),\n",
        "            \"attention_mask\": tokens.attention_mask.squeeze(0),\n",
        "        }\n",
        "\n",
        "    def _pad_or_trim(self, audio, length):\n",
        "        if len(audio) > length:\n",
        "            audio = audio[:length]\n",
        "        else:\n",
        "            audio = torch.nn.functional.pad(audio, (0, length - len(audio)))\n",
        "        return audio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Настраиваем токенизатор и пути к файлам"
      ],
      "metadata": {
        "id": "4JrxPy-bPac0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMVCHZnH9iTC"
      },
      "outputs": [],
      "source": [
        "# Используем предобученный токенизатор\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Путь к вашим данным\n",
        "tsv_path = \"/path/to/your/validated.tsv\"\n",
        "audio_dir = \"/path/to/your/clips\"\n",
        "\n",
        "# Создаем датасет и загрузчик\n",
        "dataset = AudioTextDataset(tsv_path, audio_dir, tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNet & pipelines"
      ],
      "metadata": {
        "id": "o0Y9SciRPjTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU0Q3Oaj9lCj"
      },
      "outputs": [],
      "source": [
        "# Размораживаем только UNet для обучения\n",
        "unet = pipeline.unet\n",
        "unet.train()\n",
        "\n",
        "# Замораживаем остальные части модели\n",
        "pipeline.vae.eval()\n",
        "pipeline.text_encoder.eval()\n",
        "\n",
        "# Оптимизатор\n",
        "optimizer = torch.optim.AdamW(unet.parameters(), lr=1e-5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Настройка обучения (гиперпарамаетры)"
      ],
      "metadata": {
        "id": "WrkO54oAPp9e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a1uW8W79pn8"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, unet, optimizer, epochs=3):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        pbar = tqdm(dataloader)\n",
        "        for batch in pbar:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Получаем данные\n",
        "            audio = batch['audio'].to(\"cuda\", dtype=torch.float16)\n",
        "            input_ids = batch['input_ids'].to(\"cuda\")\n",
        "            attention_mask = batch['attention_mask'].to(\"cuda\")\n",
        "\n",
        "            # Генерируем шум\n",
        "            noise = torch.randn_like(audio)\n",
        "\n",
        "            # Генерируем временные шаги\n",
        "            timesteps = torch.randint(0, pipeline.scheduler.config.num_train_timesteps, (audio.shape[0],), device=audio.device).long()\n",
        "\n",
        "            # Получаем эмбеддинги текста\n",
        "            with torch.no_grad():\n",
        "                encoder_hidden_states = pipeline.text_encoder(input_ids)[0]\n",
        "\n",
        "            # Предсказываем шум\n",
        "            noise_pred = unet(audio.unsqueeze(1), timesteps, encoder_hidden_states).sample.squeeze(1)\n",
        "\n",
        "            # Вычисляем потери\n",
        "            loss = nn.MSELoss()(noise_pred, noise)\n",
        "\n",
        "            # Обратное распространение\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.set_postfix({\"loss\": loss.item()})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ЗАПУСК ОБУЧЕНИЯ"
      ],
      "metadata": {
        "id": "je6dHqEuPv21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2RMs8C_9taG"
      },
      "outputs": [],
      "source": [
        "train_loop(dataloader, unet, optimizer, epochs=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохранение обученной модели"
      ],
      "metadata": {
        "id": "l0XJDIDYPzEh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r139kXmE9vwo"
      },
      "outputs": [],
      "source": [
        "# Сохраняем дообученный UNet\n",
        "unet.save_pretrained(\"./finetuned_unet\")\n",
        "\n",
        "# При желании можно загрузить дообученный UNet позже\n",
        "# pipeline.unet = UNetConditionalModel.from_pretrained(\"./finetuned_unet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тестирование модели"
      ],
      "metadata": {
        "id": "_dR_aCvaP3zm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgJfdUDM9xuB"
      },
      "outputs": [],
      "source": [
        "# Устанавливаем модель в режим оценки\n",
        "unet.eval()\n",
        "\n",
        "# Пример текстового запроса\n",
        "prompt = \"Пример текста для пения на русском языке\"\n",
        "\n",
        "# Токенизация текста\n",
        "tokens = tokenizer(\n",
        "    prompt,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=128,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "\n",
        "input_ids = tokens.input_ids.to(\"cuda\")\n",
        "attention_mask = tokens.attention_mask.to(\"cuda\")\n",
        "\n",
        "# Генерируем аудио\n",
        "with torch.no_grad():\n",
        "    audio_output = pipeline(\n",
        "        prompt=prompt,\n",
        "        num_inference_steps=50,\n",
        "        guidance_scale=7.5,\n",
        "        generator=torch.manual_seed(0)\n",
        "    ).audios[0]\n",
        "\n",
        "# Сохраняем аудио\n",
        "torchaudio.save(\"generated_audio.wav\", torch.tensor(audio_output).unsqueeze(0), sample_rate=16000)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}